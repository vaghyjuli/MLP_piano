{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxKmH48oqBwY"
      },
      "source": [
        "**Piano Recognition in Classical Music Using MLP**  \n",
        "  \n",
        "Alina Dima (s3919951)  \n",
        "Lisa Koopmans (s3933083)  \n",
        "Júlia Vághy (s3994759)  \n",
        "Maria Kapusheva (s3946231)  \n",
        "Group number 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGIcwYmwzmeG",
        "outputId": "86b34df5-e6a2-450f-c167-0a36bae29818"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from intervaltree import Interval, IntervalTree\n",
        "!pip install python_speech_features\n",
        "from python_speech_features import mfcc\n",
        "from python_speech_features import logfbank\n",
        "import scipy.io.wavfile as wav\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpG23A5gv5UB",
        "outputId": "ca8e7465-cd4f-421f-c82e-3dc4e1ee3df0"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umki26J68cEG",
        "tags": []
      },
      "source": [
        "**Data Preprocessing**  \n",
        "The following cell extracts the inputs (u) and the outputs (y).  \n",
        "u - a 13-dimensional vector of mel-frequency cepstrum coeffcients using 2048 window size  \n",
        "y - the label of the evaluated interval (1 - piano plays in the interval; 0 - piano does not play in the interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "VjRSGsvyxWvs",
        "outputId": "b4e28b8e-2a53-4814-fbbb-910503141074"
      },
      "outputs": [],
      "source": [
        "train_data = np.load(open('/content/drive/Shareddrives/Neural Networks/musicnet.npz','rb'), encoding = 'latin1', allow_pickle = True) # Change the path accordingly\n",
        "\n",
        "u = []\n",
        "y = []\n",
        "fs = 44100\n",
        "window_size = 2048\n",
        "stride = 1024 # represents the distance between the beginning index of consecutive intervals\n",
        "\n",
        "for key in train_data.keys():\n",
        "  signal, labels = train_data[key]\n",
        "  mfcc_feat = mfcc(signal, fs, winlen=window_size/fs, winstep=stride/fs, nfft=2048)\n",
        "  start_idx = 0\n",
        "  for i in range(mfcc_feat.shape[0]):\n",
        "    start_idx += stride\n",
        "    label = 0\n",
        "    allYInInterval = sorted(labels[start_idx:start_idx+window_size])\n",
        "    for j in range(0, len(allYInInterval)):\n",
        "      (start,end,(instrument,note,measure,beat,note_value)) = allYInInterval[j]\n",
        "      if(instrument == 1):\n",
        "        label = 1\n",
        "        break\n",
        "    y.append(label)\n",
        "  u += np.ndarray.tolist(mfcc_feat)\n",
        "\n",
        "np.save('/content/drive/Shareddrives/Neural Networks/u', u)     # Change paths accordingly\n",
        "np.save('/content/drive/Shareddrives/Neural Networks/y', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twj135rN6oJh"
      },
      "outputs": [],
      "source": [
        "u = np.load(open('/content/drive/Shareddrives/Neural Networks/u.npy','rb'), encoding = 'latin1', allow_pickle = True)  # Change paths accordingly\n",
        "y = np.load(open('/content/drive/Shareddrives/Neural Networks/y.npy','rb'), encoding = 'latin1', allow_pickle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC6x3Xnd0B4E"
      },
      "source": [
        "**Training the MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "0lXtzpO90Ox5",
        "outputId": "42b45ca2-ff50-449f-9074-b3b951d3ac86"
      },
      "outputs": [],
      "source": [
        "accuracy_per_fold = []\n",
        "loss_per_fold = []\n",
        "accuracy_history = []\n",
        "loss_history = []\n",
        "AUC_scores = []\n",
        "y_true = []\n",
        "y_predictions = []\n",
        "confusion_matrices = []\n",
        "\n",
        "# Setting up a k-fold cross validation scheme\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "kf.get_n_splits(u)\n",
        "\n",
        "# MLP training\n",
        "fold_number = 1\n",
        "for train, test in kf.split(u, y):\n",
        "  print('Fold ', fold_number)\n",
        "  fold_number += 1\n",
        "  # Model definition\n",
        "  model = Sequential()\n",
        "  model.add(Dense(9, activation='sigmoid', \n",
        "                  kernel_initializer='glorot_normal', \n",
        "                  input_shape=(13,), \n",
        "                  bias_initializer='ones', \n",
        "                  kernel_regularizer=regularizers.l2(0.2)))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Model compilation and fit\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95)\n",
        "  model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = EarlyStopping(monitor='loss', mode='min', patience=5)\n",
        "  history = model.fit(u[train], y[train],\n",
        "              batch_size=32,\n",
        "              epochs=30,\n",
        "              verbose=0,\n",
        "              callbacks=[early_stopping],\n",
        "              shuffle=True)\n",
        "\n",
        "  # Evaluate model on validation data\n",
        "  scores = model.evaluate(u[test], y[test], verbose=0)\n",
        "  accuracy_per_fold.append(scores[1])\n",
        "  loss_per_fold.append(scores[0])\n",
        "  accuracy_history += [history.history['accuracy']]\n",
        "  loss_history += [history.history['loss']]\n",
        "    \n",
        "  y_pred = (model.predict(u[test]) > 0.5).astype(\"int32\")\n",
        "  confusion_matrices += [confusion_matrix(y[test], y_pred)]\n",
        "\n",
        "  y_true.append(y[test])\n",
        "  y_predictions.append(y_pred)\n",
        "\n",
        "  # Plotting accuracy\n",
        "  plt.plot(range(1, len(history.history['accuracy'])+1), history.history['accuracy'])\n",
        "  plt.title('Accuracy History')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Value')\n",
        "  plt.show()\n",
        "    \n",
        "  # Plotting loss\n",
        "  plt.plot(range(1, len(history.history['loss'])+1), history.history['loss'])\n",
        "  plt.title('Loss History')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Value')\n",
        "  plt.show()\n",
        "    \n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfciZnOHGHD4",
        "outputId": "1ef9cbd4-8369-4174-e587-f828eb701e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.44489869475364685 - Accuracy: 81.4037024974823%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.4966578185558319 - Accuracy: 77.3828387260437%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.48799434304237366 - Accuracy: 78.54465842247009%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 79.1103998819987 (+- 1.6895529815879358)\n",
            "> Loss: 0.4765169521172841\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Mean scores\n",
        "print(f'Mean accuracy of all folds: {np.mean(accuracy_per_fold)} (+- {np.std(accuracy_per_fold)})')\n",
        "print(f'Mean loss of all folds: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qps7Icp8LF4K"
      },
      "source": [
        "Plotting the PR-curves and computing the f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz9zc19xqBwg"
      },
      "outputs": [],
      "source": [
        "f_scores = []\n",
        "# Plotting PR-curves and computing the f1 score per fold.\n",
        "for i in range(10):\n",
        "  precision, recall, _ = precision_recall_curve(y_true[i], y_predictions[i])\n",
        "  plt.plot(recall, precision, lw=1, alpha=0.6, label='PR fold %d (AUC = %0.2f)' % (i+1, average_precision_score(y_true[i], y_predictions[i])))\n",
        "  f_scores.append(f1_score(y_true[i], y_predictions[i]))\n",
        "\n",
        "y_true_all_folds = np.concatenate(y_true)\n",
        "y_predictions_all_folds = np.concatenate(y_predictions)\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true_all_folds, y_predictions_all_folds)\n",
        "\n",
        "# Getting the baseline PR-curve\n",
        "baseline = Counter(y_true_all_folds)\n",
        "baseline = baseline[1]/(baseline[1] + baseline[0])\n",
        "\n",
        "# Plotting the PR-curve over all folds and the baseline\n",
        "plt.axhline(y=baseline, linestyle='dashed', color='grey', label='PR baseline (AUC = %0.2f)'% (baseline))\n",
        "plt.plot(recall, precision, lw=2, alpha=1, label='PR all folds (AUC = %0.2f)' % (average_precision_score(y_true_all_folds, y_predictions_all_folds)), color='b')\n",
        "sn.set_style('whitegrid')\n",
        "plt.title('Precision-Recall Curves')\n",
        "plt.axis([None, None, 0, 1.1])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(loc='lower left', prop={\"size\":8.5})\n",
        "plt.show()\n",
        "\n",
        "print(f'Mean f1 score: {np.mean(f_scores)} (+- {np.std(f_scores)})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvh6bXOyhdwW"
      },
      "source": [
        "Plotting the confusion matrix and getting the FP and FN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3GEx_Aehcwq"
      },
      "outputs": [],
      "source": [
        "# source: https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
        "\n",
        "matrix = confusion_matrix(y_true_all_folds, y_predictions_all_folds)\n",
        "\n",
        "print('FP rate: %.3f' % (matrix[0][1]/(matrix[0][0] + matrix[0][1])))\n",
        "print('FN rate:  %.3f' % (matrix[1][0]/(matrix[1][0] + matrix[1][1])))\n",
        "\n",
        "df = pd.DataFrame(matrix, range(2), range(2))\n",
        "sn.set(font_scale=1.0)\n",
        "sn.heatmap(df, annot=True, annot_kws={\"size\":14}, fmt='.8g', xticklabels=['No Piano', 'Piano'], yticklabels=['No Piano', 'Piano'])\n",
        "plt.ylabel('Actual class', fontsize=14)\n",
        "plt.xlabel('Predicted class', fontsize=14)\n",
        "plt.title('Confusion matrix of stratified 10-fold cross-validation', fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ZXEwhYLb4k"
      },
      "source": [
        "Plotting accuracy and loss over all folds and per fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KHRLucr7gJ2"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  plt.plot(loss_history[i], lw=1.5, alpha=1, label='Fold %d' % (i+1))\n",
        "\n",
        "sn.set_style('whitegrid')\n",
        "plt.legend(loc='upper right', prop={\"size\":11})\n",
        "plt.title('Loss per epoch')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.savefig('Loss')\n",
        "plt.show()\n",
        "\n",
        "for i in range(10):\n",
        "  plt.plot(accuracy_history[i], lw=1, alpha=1, label='Fold %d' % (i+1))\n",
        "\n",
        "sn.set_style('whitegrid')\n",
        "plt.legend(loc='lower right', prop={\"size\":11})\n",
        "plt.title('Accuracy per epoch')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig('Accuracy')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NN_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
